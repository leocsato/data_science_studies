{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "É um algoritmo de Naive Bayes.\n",
    "É adequado para dados binários, onde cada feature pode ter apenas dois valores, como \"sim\" ou \"não\", \"0\" ou \"1\". Por exemplo, na classificação de documentos, você pode representar cada documento como um vetor de presença ou ausência de palavras-chave específicas. Esta abordagem é útil quando a presença ou ausência das características é mais importante do que sua frequência."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aqui está uma explicação passo a passo de como o Bernoulli Naive Bayes funciona:\n",
    "\n",
    "Preparação dos Dados: Os dados são representados como vetores de características binárias, onde cada característica indica a presença ou ausência de um determinado atributo. Por exemplo, em um problema de classificação de documentos, cada documento pode ser representado como um vetor onde cada entrada indica se uma palavra-chave específica está presente no documento ou não.\n",
    "Treinamento do Modelo: Durante a fase de treinamento, o modelo calcula as probabilidades a priori de cada classe e as probabilidades condicionais de cada característica dado cada classe. Essas probabilidades são estimadas a partir dos dados de treinamento.\n",
    "\n",
    "Estimação das probabilidades condicionais: Para cada característica e para cada classe, calcula-se a probabilidade de a característica ser verdadeira (1) ou falsa (0) dado que a classe é verdadeira. Isso geralmente é feito contando o número de exemplos de cada classe em que a característica está presente ou ausente e dividindo pelo número total de exemplos na classe.\n",
    "\n",
    "Cálculo das Probabilidades a Posteriori: Quando um novo exemplo (ou documento) é apresentado ao modelo, o Bernoulli Naive Bayes calcula a probabilidade a posteriori de cada classe para o exemplo dado. Isso é feito usando o Teorema de Bayes, que combina as probabilidades a priori das classes com as probabilidades condicionais das características.\n",
    "Classificação: Finalmente, o modelo atribui a classe mais provável para o novo exemplo com base nas probabilidades a posteriori calculadas. Em outras palavras, o modelo seleciona a classe que maximiza a probabilidade a posteriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T05:55:54.130986Z",
     "iopub.status.busy": "2024-04-26T05:55:54.130593Z",
     "iopub.status.idle": "2024-04-26T05:55:54.751564Z",
     "shell.execute_reply": "2024-04-26T05:55:54.750707Z",
     "shell.execute_reply.started": "2024-04-26T05:55:54.130961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(2, size=(6, 100))\n",
    "Y = np.array([1, 2, 3, 4, 4, 5])\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict(X[2:3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
